{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1989b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tonoprishvili/isc25_llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/tonoprishvili/isc25_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1c4539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  9 11:45:06 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H200 NVL                On  |   00000000:46:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             93W /  350W |    1293MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA H200 NVL                On  |   00000000:49:00.0 Off |                    0 |\n",
      "| N/A   36C    P0             95W /  350W |     531MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA H200 NVL                On  |   00000000:4E:00.0 Off |                    0 |\n",
      "| N/A   38C    P0             96W /  350W |     531MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA H200 NVL                On  |   00000000:4F:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             94W /  350W |     531MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA H200 NVL                On  |   00000000:C5:00.0 Off |                    0 |\n",
      "| N/A   39C    P0            100W /  350W |     531MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA H200 NVL                On  |   00000000:C6:00.0 Off |                    0 |\n",
      "| N/A   39C    P0             96W /  350W |     531MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA H200 NVL                On  |   00000000:C9:00.0 Off |                    0 |\n",
      "| N/A   39C    P0             96W /  350W |     531MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA H200 NVL                On  |   00000000:CF:00.0 Off |                    0 |\n",
      "| N/A   38C    P0             98W /  350W |     531MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A          229426      C   /usr/bin/python                         756MiB |\n",
      "|    0   N/A  N/A         2462036      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "|    1   N/A  N/A         2462037      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "|    2   N/A  N/A         2462038      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "|    3   N/A  N/A         2462043      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "|    4   N/A  N/A         2462044      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "|    5   N/A  N/A         2462045      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "|    6   N/A  N/A         2462046      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "|    7   N/A  N/A         2462047      C   ../../build/intelhybrid/openmx          520MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75d27d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compute_environment': 'LOCAL_MACHINE',\n",
       " 'debug': False,\n",
       " 'distributed_type': 'MULTI_GPU',\n",
       " 'downcast_bf16': 'no',\n",
       " 'enable_cpu_affinity': False,\n",
       " 'fp8_config': {'amax_compute_algorithm': 'max',\n",
       "  'amax_history_length': 1024,\n",
       "  'backend': 'TE',\n",
       "  'fp8_format': 'E4M3',\n",
       "  'interval': 1,\n",
       "  'margin': 0,\n",
       "  'override_linear_precision': [False, False, False],\n",
       "  'use_autocast_during_eval': False},\n",
       " 'gpu_ids': '0,1,2,3,4,5,6,7',\n",
       " 'machine_rank': 0,\n",
       " 'main_training_function': 'main',\n",
       " 'mixed_precision': 'fp8',\n",
       " 'num_machines': 1,\n",
       " 'num_processes': 8,\n",
       " 'rdzv_backend': 'static',\n",
       " 'same_network': True,\n",
       " 'tpu_env': [],\n",
       " 'tpu_use_cluster': False,\n",
       " 'tpu_use_sudo': False,\n",
       " 'use_cpu': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "yaml.safe_load(open('default_config.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e03f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n",
      "NVIDIA_Deep_Learning_Container_License.pdf  docker-examples\n",
      "README.md\t\t\t\t    tutorials\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformer_engine.pytorch as te\n",
    "from transformer_engine.common import recipe\n",
    "\n",
    "# Set dimensions\n",
    "in_features = 768\n",
    "out_features = 3072\n",
    "hidden_size = 2048\n",
    "\n",
    "# Initialize model and inputs.\n",
    "model = te.Linear(in_features, out_features, bias=True)\n",
    "inp = torch.randn(hidden_size, in_features, device=\"cuda\")\n",
    "\n",
    "# Create an FP8 recipe. Note: All input args are optional.\n",
    "fp8_recipe = recipe.DelayedScaling(margin=0, fp8_format=recipe.Format.E4M3)\n",
    "\n",
    "# Enable autocasting for the forward pass\n",
    "with te.fp8_autocast(enabled=True, fp8_recipe=fp8_recipe):\n",
    "    out = model(inp)\n",
    "\n",
    "loss = out.sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fddccab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-486.2162, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae5b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
