nohup: ignoring input
W0606 19:33:53.826000 49576 torch/distributed/run.py:792] 
W0606 19:33:53.826000 49576 torch/distributed/run.py:792] *****************************************
W0606 19:33:53.826000 49576 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0606 19:33:53.826000 49576 torch/distributed/run.py:792] *****************************************
2025-06-06 19:34:03,416 - INFO - Cache directories configured at: /home/tonoprishvili/hf_cache
2025-06-06 19:34:03,420 - INFO - Cache directories configured at: /home/tonoprishvili/hf_cache
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-06 19:34:03,609 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
[rank1]:[W606 19:34:04.273638045 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W606 19:34:04.470301448 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-06-06 19:34:07,562 - INFO - Initializing new model
2025-06-06 19:34:07,562 - INFO - Initializing new model

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 135.89it/s]

Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 136.42it/s]
2025-06-06 19:34:08,963 - INFO - Wrapping the model with parallelism
2025-06-06 19:34:08,963 - INFO - Wrapping the model with parallelism
2025-06-06 19:34:14,063 - INFO - Loading dataset TornikeO/cosmos_qa (all split)
2025-06-06 19:34:14,063 - INFO - Loading dataset TornikeO/cosmos_qa (all split)
2025-06-06 19:34:16,842 - INFO - Loaded 35210 examples
2025-06-06 19:34:16,843 - INFO - Training ...
2025-06-06 19:34:16,928 - INFO - Loaded 35210 examples
2025-06-06 19:34:16,928 - INFO - Training ...

  0%|          | 0/64 [00:00<?, ?it/s]
  2%|▏         | 1/64 [00:05<05:48,  5.53s/it]
  3%|▎         | 2/64 [00:10<05:09,  4.99s/it]
  5%|▍         | 3/64 [00:14<04:51,  4.78s/it]
  6%|▋         | 4/64 [00:19<04:40,  4.68s/it]
  8%|▊         | 5/64 [00:23<04:32,  4.63s/it]
  9%|▉         | 6/64 [00:28<04:26,  4.60s/it]
 11%|█         | 7/64 [00:32<04:20,  4.58s/it]
 12%|█▎        | 8/64 [00:37<04:15,  4.57s/it]
 14%|█▍        | 9/64 [00:41<04:10,  4.56s/it]
 16%|█▌        | 10/64 [00:46<04:05,  4.55s/it]
 17%|█▋        | 11/64 [00:50<04:01,  4.55s/it]
 19%|█▉        | 12/64 [00:55<03:56,  4.55s/it]
 20%|██        | 13/64 [01:00<03:52,  4.55s/it]
 22%|██▏       | 14/64 [01:04<03:47,  4.55s/it]
 23%|██▎       | 15/64 [01:09<03:43,  4.55s/it]
 25%|██▌       | 16/64 [01:13<03:38,  4.55s/it]
 27%|██▋       | 17/64 [01:18<03:33,  4.55s/it]
 28%|██▊       | 18/64 [01:22<03:29,  4.55s/it]
 30%|██▉       | 19/64 [01:27<03:24,  4.55s/it]
 31%|███▏      | 20/64 [01:31<03:20,  4.55s/it]
 33%|███▎      | 21/64 [01:36<03:15,  4.55s/it]
 34%|███▍      | 22/64 [01:41<03:11,  4.56s/it]
 36%|███▌      | 23/64 [01:45<03:06,  4.56s/it]
 38%|███▊      | 24/64 [01:50<03:02,  4.56s/it]
 39%|███▉      | 25/64 [01:54<02:57,  4.56s/it]
 41%|████      | 26/64 [01:59<02:53,  4.56s/it]
 42%|████▏     | 27/64 [02:03<02:48,  4.56s/it]
 44%|████▍     | 28/64 [02:08<02:44,  4.56s/it]
 45%|████▌     | 29/64 [02:12<02:39,  4.56s/it]
 47%|████▋     | 30/64 [02:17<02:35,  4.56s/it]
 48%|████▊     | 31/64 [02:22<02:30,  4.56s/it]
 50%|█████     | 32/64 [02:26<02:25,  4.56s/it]
 52%|█████▏    | 33/64 [02:31<02:21,  4.56s/it]
 53%|█████▎    | 34/64 [02:35<02:16,  4.56s/it]
 55%|█████▍    | 35/64 [02:40<02:12,  4.56s/it]
 56%|█████▋    | 36/64 [02:44<02:07,  4.56s/it]
 58%|█████▊    | 37/64 [02:49<02:03,  4.56s/it]
 59%|█████▉    | 38/64 [02:54<01:58,  4.56s/it]
 61%|██████    | 39/64 [02:58<01:54,  4.56s/it]
 62%|██████▎   | 40/64 [03:03<01:49,  4.56s/it]
 64%|██████▍   | 41/64 [03:07<01:44,  4.56s/it]
 66%|██████▌   | 42/64 [03:12<01:40,  4.56s/it]
 67%|██████▋   | 43/64 [03:16<01:35,  4.56s/it]
 69%|██████▉   | 44/64 [03:21<01:31,  4.57s/it]
 70%|███████   | 45/64 [03:26<01:26,  4.56s/it]
 72%|███████▏  | 46/64 [03:30<01:22,  4.57s/it]
 73%|███████▎  | 47/64 [03:35<01:17,  4.57s/it]
 75%|███████▌  | 48/64 [03:39<01:13,  4.56s/it]
 77%|███████▋  | 49/64 [03:44<01:08,  4.56s/it]
 78%|███████▊  | 50/64 [03:48<01:03,  4.56s/it]
 80%|███████▉  | 51/64 [03:53<00:59,  4.56s/it]
 81%|████████▏ | 52/64 [03:57<00:54,  4.56s/it]
 83%|████████▎ | 53/64 [04:02<00:50,  4.56s/it]
 84%|████████▍ | 54/64 [04:07<00:45,  4.56s/it]
 86%|████████▌ | 55/64 [04:11<00:41,  4.56s/it]
 88%|████████▊ | 56/64 [04:16<00:36,  4.57s/it]
 89%|████████▉ | 57/64 [04:20<00:31,  4.57s/it]
 91%|█████████ | 58/64 [04:25<00:27,  4.57s/it]
 92%|█████████▏| 59/64 [04:29<00:22,  4.56s/it]
 94%|█████████▍| 60/64 [04:34<00:18,  4.56s/it]
 95%|█████████▌| 61/64 [04:39<00:13,  4.56s/it]
 97%|█████████▋| 62/64 [04:43<00:09,  4.56s/it]
 98%|█████████▊| 63/64 [04:48<00:04,  4.56s/it]
100%|██████████| 64/64 [04:52<00:00,  4.56s/it]
                                               
{'loss': 1.5054, 'grad_norm': 0.9892734885215759, 'learning_rate': 3.125e-06, 'epoch': 0.35}

100%|██████████| 64/64 [04:52<00:00,  4.56s/it]
                                               
{'train_runtime': 294.5189, 'train_samples_per_second': 41.722, 'train_steps_per_second': 0.217, 'train_loss': 1.5053836107254028, 'epoch': 0.35}

100%|██████████| 64/64 [04:54<00:00,  4.56s/it]
100%|██████████| 64/64 [04:54<00:00,  4.60s/it]
2025-06-06 19:39:12,250 - INFO - Total training time: 294.94 seconds
2025-06-06 19:39:12,485 - INFO - Checkpointing from local_rank = 0 ...
2025-06-06 19:39:12,842 - INFO - DONE: local_rank = 1
2025-06-06 19:39:13,474 - INFO - DONE: local_rank = 0
