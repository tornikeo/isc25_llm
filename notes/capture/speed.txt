W0606 18:42:20.085000 31278 torch/distributed/run.py:792] 
W0606 18:42:20.085000 31278 torch/distributed/run.py:792] *****************************************
W0606 18:42:20.085000 31278 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0606 18:42:20.085000 31278 torch/distributed/run.py:792] *****************************************
2025-06-06 18:42:25,963 - INFO - Cache directories configured at: /home/tonoprishvili/hf_cache
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-06 18:42:26,577 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-06 18:42:27,057 - INFO - Cache directories configured at: /home/tonoprishvili/hf_cache
2025-06-06 18:42:27,058 - INFO - Cache directories configured at: /home/tonoprishvili/hf_cache
2025-06-06 18:42:27,065 - INFO - Cache directories configured at: /home/tonoprishvili/hf_cache
[rank0]:[W606 18:42:27.592378943 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W606 18:42:27.691199700 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W606 18:42:27.697668673 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W606 18:42:27.704170426 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-06-06 18:42:30,935 - INFO - Initializing new model
2025-06-06 18:42:30,936 - INFO - Initializing new model
2025-06-06 18:42:30,936 - INFO - Initializing new model
2025-06-06 18:42:30,936 - INFO - Initializing new model
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 139.46it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 141.40it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 135.64it/s]

Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 141.95it/s]
2025-06-06 18:42:32,286 - INFO - Wrapping the model with parallelism
2025-06-06 18:42:32,286 - INFO - Wrapping the model with parallelism
2025-06-06 18:42:32,286 - INFO - Wrapping the model with parallelism
2025-06-06 18:42:32,286 - INFO - Wrapping the model with parallelism
2025-06-06 18:42:34,430 - INFO - Loading dataset TornikeO/cosmos_qa (all split)
2025-06-06 18:42:34,430 - INFO - Loading dataset TornikeO/cosmos_qa (all split)
2025-06-06 18:42:34,430 - INFO - Loading dataset TornikeO/cosmos_qa (all split)
2025-06-06 18:42:34,430 - INFO - Loading dataset TornikeO/cosmos_qa (all split)
2025-06-06 18:42:36,774 - INFO - Loaded 35210 examples
2025-06-06 18:42:36,774 - INFO - Training ...
2025-06-06 18:42:37,039 - INFO - Loaded 35210 examples
2025-06-06 18:42:37,039 - INFO - Training ...
2025-06-06 18:42:37,744 - INFO - Loaded 35210 examples
2025-06-06 18:42:37,744 - INFO - Training ...
2025-06-06 18:42:38,748 - INFO - Loaded 35210 examples
2025-06-06 18:42:38,748 - INFO - Training ...
  0%|          | 0/92 [00:00<?, ?it/s]  1%|          | 1/92 [00:04<07:21,  4.85s/it]  2%|▏         | 2/92 [00:09<07:00,  4.67s/it]  3%|▎         | 3/92 [00:13<06:50,  4.61s/it]  4%|▍         | 4/92 [00:18<06:43,  4.59s/it]  5%|▌         | 5/92 [00:23<06:38,  4.58s/it]  7%|▋         | 6/92 [00:27<06:33,  4.58s/it]  8%|▊         | 7/92 [00:32<06:28,  4.57s/it]  9%|▊         | 8/92 [00:36<06:24,  4.57s/it] 10%|▉         | 9/92 [00:41<06:19,  4.57s/it] 11%|█         | 10/92 [00:45<06:15,  4.57s/it] 12%|█▏        | 11/92 [00:50<06:10,  4.58s/it] 13%|█▎        | 12/92 [00:55<06:06,  4.58s/it] 14%|█▍        | 13/92 [00:59<06:02,  4.58s/it] 15%|█▌        | 14/92 [01:04<05:57,  4.58s/it] 16%|█▋        | 15/92 [01:08<05:53,  4.59s/it] 17%|█▋        | 16/92 [01:13<05:48,  4.59s/it] 18%|█▊        | 17/92 [01:18<05:44,  4.59s/it] 20%|█▉        | 18/92 [01:22<05:39,  4.59s/it] 21%|██        | 19/92 [01:27<05:35,  4.59s/it] 22%|██▏       | 20/92 [01:31<05:30,  4.60s/it] 23%|██▎       | 21/92 [01:36<05:26,  4.60s/it] 24%|██▍       | 22/92 [01:41<05:21,  4.60s/it] 25%|██▌       | 23/92 [01:45<05:17,  4.60s/it] 26%|██▌       | 24/92 [01:50<05:13,  4.60s/it] 27%|██▋       | 25/92 [01:54<05:08,  4.61s/it] 28%|██▊       | 26/92 [01:59<05:04,  4.61s/it] 29%|██▉       | 27/92 [02:04<04:59,  4.61s/it] 30%|███       | 28/92 [02:08<04:54,  4.61s/it] 32%|███▏      | 29/92 [02:13<04:50,  4.61s/it] 33%|███▎      | 30/92 [02:17<04:45,  4.61s/it] 34%|███▎      | 31/92 [02:22<04:41,  4.61s/it] 35%|███▍      | 32/92 [02:27<04:36,  4.61s/it] 36%|███▌      | 33/92 [02:31<04:32,  4.61s/it] 37%|███▋      | 34/92 [02:36<04:27,  4.61s/it] 38%|███▊      | 35/92 [02:40<04:22,  4.61s/it] 39%|███▉      | 36/92 [02:45<04:18,  4.61s/it] 40%|████      | 37/92 [02:50<04:13,  4.61s/it] 41%|████▏     | 38/92 [02:54<04:09,  4.61s/it] 42%|████▏     | 39/92 [02:59<04:04,  4.61s/it] 43%|████▎     | 40/92 [03:04<03:59,  4.61s/it] 45%|████▍     | 41/92 [03:08<03:55,  4.62s/it] 46%|████▌     | 42/92 [03:13<03:50,  4.62s/it] 47%|████▋     | 43/92 [03:17<03:46,  4.62s/it] 48%|████▊     | 44/92 [03:22<03:41,  4.62s/it] 49%|████▉     | 45/92 [03:27<03:37,  4.62s/it] 50%|█████     | 46/92 [03:31<03:32,  4.62s/it] 51%|█████     | 47/92 [03:36<03:27,  4.62s/it] 52%|█████▏    | 48/92 [03:41<03:23,  4.62s/it] 53%|█████▎    | 49/92 [03:45<03:18,  4.62s/it] 54%|█████▍    | 50/92 [03:50<03:14,  4.62s/it] 55%|█████▌    | 51/92 [03:54<03:09,  4.62s/it] 57%|█████▋    | 52/92 [03:59<03:04,  4.62s/it] 58%|█████▊    | 53/92 [04:04<03:00,  4.62s/it] 59%|█████▊    | 54/92 [04:08<02:55,  4.62s/it] 60%|█████▉    | 55/92 [04:13<02:50,  4.62s/it] 61%|██████    | 56/92 [04:17<02:46,  4.62s/it] 62%|██████▏   | 57/92 [04:22<02:41,  4.62s/it] 63%|██████▎   | 58/92 [04:27<02:37,  4.62s/it] 64%|██████▍   | 59/92 [04:31<02:32,  4.62s/it] 65%|██████▌   | 60/92 [04:36<02:27,  4.62s/it] 66%|██████▋   | 61/92 [04:41<02:23,  4.62s/it] 67%|██████▋   | 62/92 [04:45<02:18,  4.62s/it] 68%|██████▊   | 63/92 [04:50<02:13,  4.62s/it] 70%|██████▉   | 64/92 [04:54<02:09,  4.62s/it] 71%|███████   | 65/92 [04:59<02:04,  4.62s/it] 72%|███████▏  | 66/92 [05:04<02:00,  4.62s/it] 73%|███████▎  | 67/92 [05:08<01:55,  4.62s/it] 74%|███████▍  | 68/92 [05:13<01:50,  4.62s/it] 75%|███████▌  | 69/92 [05:18<01:46,  4.62s/it] 76%|███████▌  | 70/92 [05:22<01:41,  4.62s/it] 77%|███████▋  | 71/92 [05:27<01:37,  4.62s/it] 78%|███████▊  | 72/92 [05:31<01:32,  4.62s/it] 79%|███████▉  | 73/92 [05:36<01:27,  4.62s/it] 80%|████████  | 74/92 [05:41<01:23,  4.62s/it] 82%|████████▏ | 75/92 [05:45<01:18,  4.62s/it] 83%|████████▎ | 76/92 [05:50<01:13,  4.62s/it] 84%|████████▎ | 77/92 [05:55<01:09,  4.62s/it] 85%|████████▍ | 78/92 [05:59<01:04,  4.62s/it] 86%|████████▌ | 79/92 [06:04<01:00,  4.64s/it] 87%|████████▋ | 80/92 [06:08<00:55,  4.64s/it] 88%|████████▊ | 81/92 [06:13<00:50,  4.63s/it] 89%|████████▉ | 82/92 [06:18<00:47,  4.74s/it] 90%|█████████ | 83/92 [06:23<00:43,  4.85s/it] 91%|█████████▏| 84/92 [06:29<00:40,  5.01s/it] 92%|█████████▏| 85/92 [06:34<00:35,  5.13s/it] 93%|█████████▎| 86/92 [06:39<00:31,  5.23s/it] 95%|█████████▍| 87/92 [06:45<00:26,  5.27s/it] 96%|█████████▌| 88/92 [06:50<00:21,  5.29s/it] 97%|█████████▋| 89/92 [06:56<00:15,  5.32s/it] 98%|█████████▊| 90/92 [07:01<00:10,  5.35s/it] 99%|█████████▉| 91/92 [07:06<00:05,  5.36s/it]100%|██████████| 92/92 [07:10<00:00,  4.94s/it]                                               {'loss': 1.1445, 'grad_norm': 0.884495735168457, 'learning_rate': 2.173913043478261e-06, 'epoch': 1.0}
100%|██████████| 92/92 [07:10<00:00,  4.94s/it]                                               {'train_runtime': 432.5148, 'train_samples_per_second': 81.408, 'train_steps_per_second': 0.213, 'train_loss': 1.1444854736328125, 'epoch': 1.0}
100%|██████████| 92/92 [07:12<00:00,  4.94s/it]100%|██████████| 92/92 [07:12<00:00,  4.70s/it]
2025-06-06 18:49:51,666 - INFO - Total training time: 434.47 seconds
2025-06-06 18:49:51,912 - INFO - Checkpointing from local_rank = 0 ...
2025-06-06 18:49:52,611 - INFO - DONE: local_rank = 2
2025-06-06 18:49:52,611 - INFO - DONE: local_rank = 1
2025-06-06 18:49:52,612 - INFO - DONE: local_rank = 3
2025-06-06 18:49:52,963 - INFO - DONE: local_rank = 0
